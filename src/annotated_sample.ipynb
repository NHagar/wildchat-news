{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score, balanced_accuracy_score\n",
    "import tiktoken\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920520,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(*) FROM '../data/wildchat.parquet'\").fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826406,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(DISTINCT conversation_hash) FROM '../data/wildchat.parquet'\").fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265419,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(*) FROM '../data/wildchat.parquet' WHERE country = 'United States' AND role = 'user' AND language = 'English'\").fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(DISTINCT conversation_hash)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(DISTINCT conversation_hash)\n",
       "0                             146164"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(DISTINCT conversation_hash) FROM '../data/wildchat.parquet' WHERE country = 'United States' AND role = 'user' AND language = 'English'\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random annotation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  count_star()\n",
       "0               0           992\n",
       "1               1             8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT classification, COUNT(*) FROM '../data/sample_for_annotation_annotated.csv' GROUP BY classification\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted search sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/searched_news.txt\", \"r\") as f:\n",
    "    records = f.read()\n",
    "\n",
    "print(len(records.split(\"---\")) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./prompts/classification.txt\", \"r\") as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare human annotations for LLM performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = con.execute(\"SELECT content, classification FROM '../data/sample_for_annotation_annotated.csv'\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched = pd.DataFrame([r.strip() for r in records.split(\"---\")[:-1]], columns=[\"content\"])\n",
    "searched[\"classification\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.concat([annotations, searched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "0    992\n",
       "1     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LLM evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [28:41<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs_mini = []\n",
    "outputs_o = []\n",
    "for _, s in tqdm(annotations.iterrows(), total=len(annotations)):\n",
    "    resp = llm.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"[MESSAGE]{s.content}[\\\\MESSAGE]\"},\n",
    "        ]\n",
    "    )\n",
    "    outputs_mini.append(resp.choices[0].message.content)\n",
    "    resp = llm.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"[MESSAGE]{s.content}[\\\\MESSAGE]\"},\n",
    "        ]\n",
    "    )\n",
    "    outputs_o.append(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[\"gpt-4o-mini\"] = outputs_mini\n",
    "annotations[\"gpt-4o\"] = outputs_o\n",
    "annotations.to_csv(\"../data/sample_for_annotation_annotated_llm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_classification(output):\n",
    "    clf = output.split(\"\\n\")[0]\n",
    "    try:\n",
    "        return int(clf)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[\"clf_gpt-4o-mini\"] = annotations[\"gpt-4o-mini\"].apply(extract_classification)\n",
    "annotations[\"clf_gpt-4o\"] = annotations[\"gpt-4o\"].apply(extract_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 0 if not found (1 record)\n",
    "annotations.loc[annotations[\"clf_gpt-4o\"].isna(), \"clf_gpt-4o\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clf_gpt-4o-mini\n",
       "0    974\n",
       "1     84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"clf_gpt-4o-mini\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clf_gpt-4o\n",
       "0.0    940\n",
       "1.0    118\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"clf_gpt-4o\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       992\n",
      "           1       0.71      0.91      0.80        66\n",
      "\n",
      "    accuracy                           0.97      1058\n",
      "   macro avg       0.85      0.94      0.89      1058\n",
      "weighted avg       0.98      0.97      0.97      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(annotations[\"classification\"], annotations[\"clf_gpt-4o-mini\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       992\n",
      "           1       0.54      0.97      0.70        66\n",
      "\n",
      "    accuracy                           0.95      1058\n",
      "   macro avg       0.77      0.96      0.83      1058\n",
      "weighted avg       0.97      0.95      0.95      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(annotations[\"classification\"], annotations[\"clf_gpt-4o\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732161297828683\n",
      "0.9538368811813375\n",
      "0.9424486803519061\n",
      "0.957630742913001\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(annotations[\"classification\"], annotations[\"clf_gpt-4o-mini\"], average=\"weighted\"))\n",
    "print(f1_score(annotations[\"classification\"], annotations[\"clf_gpt-4o\"], average=\"weighted\"))\n",
    "print(balanced_accuracy_score(annotations[\"classification\"], annotations[\"clf_gpt-4o-mini\"]))\n",
    "print(balanced_accuracy_score(annotations[\"classification\"], annotations[\"clf_gpt-4o\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimate for entire sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 66777553\n",
      "Cost: $10.02\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "all_user_messages = con.execute(\"SELECT content FROM '../data/wildchat.parquet' WHERE country = 'United States' AND role = 'user' AND language = 'English'\").fetchdf()\n",
    "all_tokens = sum([len(enc.encode(m, disallowed_special=())) for m in all_user_messages.content])\n",
    "print(f\"Total tokens: {all_tokens}\")\n",
    "print(f\"Cost: ${all_tokens * 0.15 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 32158\n",
      "Cost per record: $0.00\n",
      "Total cost: $5.02\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "all_outputs = con.execute(\"\"\"SELECT \"gpt-4o-mini\" FROM '../data/sample_for_annotation_annotated_llm.csv'\"\"\").fetchdf()\n",
    "all_tokens = sum([len(enc.encode(m, disallowed_special=())) for m in all_outputs[\"gpt-4o-mini\"]])\n",
    "print(f\"Total tokens: {all_tokens}\")\n",
    "cost_per_record = all_tokens * 0.6 / 1_000_000 / len(all_outputs)\n",
    "print(f\"Cost per record: ${cost_per_record:.2f}\")\n",
    "print(f\"Total cost: ${cost_per_record * len(all_user_messages):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM annotate entire sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>1960260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistant</td>\n",
       "      <td>1960260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        role  count_star()\n",
       "0       user       1960260\n",
       "1  assistant       1960260"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT role, COUNT(*) FROM '../data/wildchat.parquet' GROUP BY role\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_hash</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [conversation_hash, content]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"SELECT conversation_hash, content FROM '../data/wildchat.parquet' \n",
    "            WHERE country = 'United States' AND role = 'user' AND language = 'English'\n",
    "            AND conversation_hash NOT IN (SELECT conversation_hash FROM '../data/sample_for_annotation_annotated.csv')\n",
    "            AND content NOT IN (SELECT content FROM '../data/sample_for_annotation_annotated_llm.csv')\"\"\").fetch_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            AND content NOT IN (SELECT content FROM '../data/sample_for_annotation_annotated_llm.csv')\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
