{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(\"\"\"SELECT DISTINCT conversation_hash, content FROM '../data/wildchat.parquet' JOIN '../data/nomic_filter_broad.csv' USING(conversation_hash) WHERE country = 'United States' AND role = 'user';\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"classification\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"../data/sample_for_annotation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_star()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_star()\n",
       "0             8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(*) FROM '../data/sample_for_annotation_annotated.csv' WHERE classification = 1\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\n",
    "    \"news\",\n",
    "    \"new york times\",\n",
    "    \"bbc\",\n",
    "    \"ukraine\",\n",
    "    \"breaking\",\n",
    "    \"cnn\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/cp3f18nd7896mtv8sdjnzw500000gp/T/ipykernel_45949/2454483039.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targeted[\"classification\"] = \"\"\n"
     ]
    }
   ],
   "source": [
    "# search for search terms in lowercased content\n",
    "targeted = df[df[\"content\"].str.lower().str.contains(\"|\".join(search_terms))]\n",
    "targeted[\"classification\"] = \"\"\n",
    "targeted.to_csv(\"../data/targeted_for_annotation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(\"../data/targeted_for_annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.concat([annotations, pd.read_csv(\"../data/sample_for_annotation_annotated.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/searched_news.txt\", \"r\") as f:\n",
    "    st = f.read().split(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.concat([annotations, pd.DataFrame({\"conversation_hash\": [\"\"] * len(st), \"content\": st, \"classification\": [1] * len(st)})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 9 to 0\n",
    "annotations[\"classification\"] = annotations[\"classification\"].replace(9, 0)\n",
    "annotations = annotations[annotations.classification.notna()].drop_duplicates(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an AI assistant designed to classify user messages as either news-related (1) or not news-related (0). Your task is to analyze each message and determine if it pertains to news, current events, or information seeking about news sources.\n",
    "Classification Guidelines:\n",
    "\n",
    "Classify as news-related (1):\n",
    "\n",
    "Messages seeking information about news sources\n",
    "Questions about current events or recent happenings\n",
    "Requests for updates on any topic that could be considered news\n",
    "Inquiries about reputable news outlets or publications\n",
    "Messages mentioning specific news events or asking for news summaries\n",
    "Requests for information that would typically be found in news articles\n",
    "Any message that mentions news, even if it's not the primary focus (err on the side of including ambiguous cases)\n",
    "\n",
    "\n",
    "Classify as not news-related (0):\n",
    "\n",
    "Personal questions or statements unrelated to current events\n",
    "Requests for advice on personal matters\n",
    "Fiction-related queries or creative writing prompts\n",
    "Technical questions unrelated to news (e.g., coding, math)\n",
    "General knowledge questions that aren't tied to current events\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "Provide only a binary output: 1 for news-related, 0 for not news-related\n",
    "Include a brief explanation for your classification, focusing on the intent and content of the message\n",
    "\n",
    "\n",
    "Important Notes:\n",
    "\n",
    "Consider all news topics equally relevant (politics, sports, entertainment, etc.)\n",
    "If a message contains both news-related and unrelated content, classify it as news-related (1)\n",
    "Focus on the intent and content of the message, not on the specific sources mentioned\n",
    "The message you are meant to classify will be wrapped in these tags: [MESSAGE]...[/MESSAGE]\n",
    "\n",
    "\n",
    "\n",
    "Examples:\n",
    "\n",
    "\"Please list ten websites where I can find bilingual magazines both in Chinese and English for free download. The magazines should be as well-known as 'New York Times' and 'The Economist', and the information therein should be based on authoritative and reliable sources.\" -> 1\n",
    "\"Where to get FHA loan.\" -> 0\n",
    "\"Name a few major events in the middle east from 2020 from the BBC.\" -> 1\n",
    "\"Make Season 1 Episode 14 about Tommy and The Girls hanging out again, and Momo comes close to Tommy hugging him and caring for a him, and giving him a soft kiss on the lips\" -> 0\n",
    "\n",
    "Your task is to classify each message accurately based on these guidelines.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LLM annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1255/1255 [20:38<00:00,  1.01it/s] \n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for _, s in tqdm(annotations.iterrows(), total=len(annotations)):\n",
    "    resp = oai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"[MESSAGE]{s.content}[\\\\MESSAGE]\"},\n",
    "        ]\n",
    "    )\n",
    "    outputs.append(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(text):\n",
    "    try:\n",
    "        return int(text.split(\"\\n\")[0])\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[\"llm_output\"] = outputs\n",
    "annotations[\"llm_clf\"] = annotations.llm_output.apply(get_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = annotations.loc[annotations.llm_clf.notna(), [\"classification\", \"llm_clf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6896551724137931)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(scores.classification, scores.llm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9223530775696329)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(scores.classification, scores.llm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand LLM annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sample = con.execute(\"\"\"WITH init AS (\n",
    "            SELECT DISTINCT \n",
    "                conversation_hash, \n",
    "                content \n",
    "            FROM \n",
    "                '../data/wildchat.parquet' \n",
    "            JOIN '../data/nomic_filter_broad.csv' \n",
    "            USING(conversation_hash) \n",
    "            WHERE \n",
    "                country = 'United States' \n",
    "                AND role = 'user' \n",
    "                AND conversation_hash NOT IN (SELECT conversation_hash FROM annotations)\n",
    "        )\n",
    "            SELECT * FROM init\n",
    "            USING SAMPLE 5000\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [1:00:12<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for _, s in tqdm(llm_sample.iterrows(), total=len(llm_sample)):\n",
    "    resp = oai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"[MESSAGE]{s.content}[\\\\MESSAGE]\"},\n",
    "        ]\n",
    "    )\n",
    "    outputs.append(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sample[\"llm_output\"] = outputs\n",
    "llm_sample[\"llm_clf\"] = llm_sample.llm_output.apply(get_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sample[\"classification\"] = llm_sample.llm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([annotations, llm_sample]).to_csv(\"../data/annotations_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
